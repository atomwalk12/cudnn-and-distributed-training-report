
@misc{chetlur_cudnn_2014,
	title = {{cuDNN}: {Efficient} {Primitives} for {Deep} {Learning}},
	shorttitle = {{cuDNN}},
	url = {http://arxiv.org/abs/1410.0759},
	doi = {10.48550/arXiv.1410.0759},
	abstract = {We present a library of efficient implementations of deep learning primitives. Deep learning workloads are computationally intensive, and optimizing their kernels is difficult and time-consuming. As parallel architectures evolve, kernels must be reoptimized, which makes maintaining codebases difficult over time. Similar issues have long been addressed in the HPC community by libraries such as the Basic Linear Algebra Subroutines (BLAS). However, there is no analogous library for deep learning. Without such a library, researchers implementing deep learning workloads on parallel processors must create and optimize their own implementations of the main computational kernels, and this work must be repeated as new parallel processors emerge. To address this problem, we have created a library similar in intent to BLAS, with optimized routines for deep learning workloads. Our implementation contains routines for GPUs, although similarly to the BLAS library, these routines could be implemented for other platforms. The library is easy to integrate into existing frameworks, and provides optimized performance and memory usage. For example, integrating cuDNN into Caffe, a popular framework for convolutional networks, improves performance by 36\% on a standard model while also reducing memory consumption.},
	urldate = {2024-12-19},
	publisher = {arXiv},
	author = {Chetlur, Sharan and Woolley, Cliff and Vandermersch, Philippe and Cohen, Jonathan and Tran, John and Catanzaro, Bryan and Shelhamer, Evan},
	month = dec,
	year = {2014},
	note = {arXiv:1410.0759 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Mathematical Software, Computer Science - Neural and Evolutionary Computing},
	file = {Preprint PDF:/home/atomwalk12/Zotero/storage/RL3D3MXP/Chetlur et al. - 2014 - cuDNN Efficient Primitives for Deep Learning.pdf:application/pdf;Snapshot:/home/atomwalk12/Zotero/storage/EBSM39I9/1410.html:text/html},
}

@misc{krizhevsky_one_2014,
	title = {One weird trick for parallelizing convolutional neural networks},
	url = {http://arxiv.org/abs/1404.5997},
	doi = {10.48550/arXiv.1404.5997},
	abstract = {I present a new way to parallelize the training of convolutional neural networks across multiple GPUs. The method scales significantly better than all alternatives when applied to modern convolutional neural networks.},
	urldate = {2024-12-19},
	publisher = {arXiv},
	author = {Krizhevsky, Alex},
	month = apr,
	year = {2014},
	note = {arXiv:1404.5997 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {Preprint PDF:/home/atomwalk12/Zotero/storage/ZQGF4UVN/Krizhevsky - 2014 - One weird trick for parallelizing convolutional neural networks.pdf:application/pdf;Snapshot:/home/atomwalk12/Zotero/storage/QUFUCVLP/1404.html:text/html},
}

@misc{jia_caffe_2014,
	title = {Caffe: {Convolutional} {Architecture} for {Fast} {Feature} {Embedding}},
	shorttitle = {Caffe},
	url = {http://arxiv.org/abs/1408.5093},
	doi = {10.48550/arXiv.1408.5093},
	abstract = {Caﬀe provides multimedia scientists and practitioners with a clean and modiﬁable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying generalpurpose convolutional neural networks and other deep models eﬃciently on commodity architectures. Caﬀe ﬁts industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (≈ 2.5 ms per image). By separating model representation from actual implementation, Caﬀe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.},
	language = {en},
	urldate = {2024-12-27},
	publisher = {arXiv},
	author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
	month = jun,
	year = {2014},
	note = {arXiv:1408.5093 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:/home/atomwalk12/Zotero/storage/TFCGA4KC/Jia et al. - 2014 - Caffe Convolutional Architecture for Fast Feature Embedding.pdf:application/pdf},
}

@article{paszke_automatic_nodate,
	title = {Automatic differentiation in {PyTorch}},
	abstract = {In this article, we describe an automatic differentiation module of PyTorch — a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and HIPS Autograd [4], and provides a high performance environment with easy access to automatic differentiation of models executed on different devices (CPU and GPU). To make prototyping easier, PyTorch does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all PyTorch features.},
	language = {en},
	author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban},
	file = {PDF:/home/atomwalk12/Zotero/storage/NIPIP9DT/Paszke et al. - Automatic differentiation in PyTorch.pdf:application/pdf},
}

@article{verbraeken_survey_2021,
	title = {A {Survey} on {Distributed} {Machine} {Learning}},
	volume = {53},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3377454},
	doi = {10.1145/3377454},
	abstract = {The demand for artificial intelligence has grown significantly over the past decade, and this growth has been fueled by advances in machine learning techniques and the ability to leverage hardware acceleration. However, to increase the quality of predictions and render machine learning solutions feasible for more complex applications, a substantial amount of training data is required. Although small machine learning models can be trained with modest amounts of data, the input for training larger models such as neural networks grows exponentially with the number of parameters. Since the demand for processing training data has outpaced the increase in computation power of computing machinery, there is a need for distributing the machine learning workload across multiple machines, and turning the centralized into a distributed system. These distributed systems present new challenges: first and foremost, the efficient parallelization of the training process and the creation of a coherent model. This article provides an extensive overview of the current state-of-the-art in the field by outlining the challenges and opportunities of distributed machine learning over conventional (centralized) machine learning, discussing the techniques used for distributed machine learning, and providing an overview of the systems that are available.},
	language = {en},
	number = {2},
	urldate = {2024-12-27},
	journal = {ACM Computing Surveys},
	author = {Verbraeken, Joost and Wolting, Matthijs and Katzy, Jonathan and Kloppenburg, Jeroen and Verbelen, Tim and Rellermeyer, Jan S.},
	month = mar,
	year = {2021},
	pages = {1--33},
	file = {PDF:/home/atomwalk12/Zotero/storage/6MFPCFG2/Verbraeken et al. - 2021 - A Survey on Distributed Machine Learning.pdf:application/pdf},
}

@article{ben-nun_demystifying_2020,
	title = {Demystifying {Parallel} and {Distributed} {Deep} {Learning}: {An} {In}-depth {Concurrency} {Analysis}},
	volume = {52},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Demystifying {Parallel} and {Distributed} {Deep} {Learning}},
	url = {https://dl.acm.org/doi/10.1145/3320060},
	doi = {10.1145/3320060},
	abstract = {Deep Neural Networks (DNNs) are becoming an important tool in modern computing applications. Accelerating their training is a major challenge and techniques range from distributed algorithms to low-level circuit design. In this survey, we describe the problem from a theoretical perspective, followed by approaches for its parallelization. We present trends in DNN architectures and the resulting implications on parallelization strategies. We then review and model the different types of concurrency in DNNs: from the single operator, through parallelism in network inference and training, to distributed deep learning. We discuss asynchronous stochastic optimization, distributed system architectures, communication schemes, and neural architecture search. Based on those approaches, we extrapolate potential directions for parallelism in deep learning.},
	language = {en},
	number = {4},
	urldate = {2024-12-27},
	journal = {ACM Computing Surveys},
	author = {Ben-Nun, Tal and Hoefler, Torsten},
	month = jul,
	year = {2020},
	pages = {1--43},
	file = {PDF:/home/atomwalk12/Zotero/storage/GBBDSCCF/Ben-Nun and Hoefler - 2020 - Demystifying Parallel and Distributed Deep Learning An In-depth Concurrency Analysis.pdf:application/pdf},
}

@misc{chahal_hitchhikers_2018,
	title = {A {Hitchhiker}'s {Guide} {On} {Distributed} {Training} of {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1810.11787},
	doi = {10.48550/arXiv.1810.11787},
	abstract = {Deep learning has led to tremendous advancements in the ﬁeld of Artiﬁcial Intelligence. One caveat however is the substantial amount of compute needed to train these deep learning models. Training a benchmark dataset like ImageNet on a single machine with a modern GPU can take upto a week, distributing training on multiple machines has been observed to drastically bring this time down. Recent work has brought down ImageNet training time to a time as low as 4 minutes by using a cluster of 2048 GPUs. This paper surveys the various algorithms and techniques used to distribute training and presents the current state of the art for a modern distributed training framework. More speciﬁcally, we explore the synchronous and asynchronous variants of distributed Stochastic Gradient Descent, various All Reduce gradient aggregation strategies and best practices for obtaining higher throughout and lower latency over a cluster such as mixed precision training, large batch training and gradient compression.},
	language = {en},
	urldate = {2024-12-27},
	publisher = {arXiv},
	author = {Chahal, Karanbir and Grover, Manraj Singh and Dey, Kuntal},
	month = oct,
	year = {2018},
	note = {arXiv:1810.11787 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:/home/atomwalk12/Zotero/storage/7HZX2TRH/Chahal et al. - 2018 - A Hitchhiker's Guide On Distributed Training of Deep Neural Networks.pdf:application/pdf},
}

@misc{nichols_survey_2022,
	title = {A {Survey} and {Empirical} {Evaluation} of {Parallel} {Deep} {Learning} {Frameworks}},
	url = {http://arxiv.org/abs/2111.04949},
	doi = {10.48550/arXiv.2111.04949},
	abstract = {The field of deep learning has witnessed a remarkable shift towards extremely compute- and memory-intensive neural networks. These newer larger models have enabled researchers to advance stateof-the-art tools across a variety of fields. This phenomenon has spurred the development of algorithms for distributed training of neural networks over a larger number of hardware accelerators. In this paper, we discuss and compare current state-of-the-art frameworks for large scale distributed deep learning. First, we survey current practices in distributed learning and identify the different types of parallelism used. Then, we present empirical results comparing their performance on large image and language training tasks. Additionally, we address their statistical efficiency and memory consumption behavior. Based on our results, we discuss algorithmic and implementation portions of each framework which hinder performance.},
	language = {en},
	urldate = {2024-12-27},
	publisher = {arXiv},
	author = {Nichols, Daniel and Singh, Siddharth and Lin, Shu-Huai and Bhatele, Abhinav},
	month = jul,
	year = {2022},
	note = {arXiv:2111.04949 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Artificial Intelligence},
	file = {PDF:/home/atomwalk12/Zotero/storage/JWXILBYW/Nichols et al. - 2022 - A Survey and Empirical Evaluation of Parallel Deep Learning Frameworks.pdf:application/pdf},
}

@incollection{li_deep_2016,
	title = {Deep {Learning} and {Its} {Parallelization}},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-0-12-805394-2},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128053942000040},
	language = {en},
	urldate = {2024-12-27},
	booktitle = {Big {Data}},
	publisher = {Elsevier},
	author = {Li, X. and Zhang, G. and Li, K. and Zheng, W.},
	year = {2016},
	doi = {10.1016/B978-0-12-805394-2.00004-0},
	pages = {95--118},
	file = {PDF:/home/atomwalk12/Zotero/storage/GX9SFI95/Li et al. - 2016 - Deep Learning and Its Parallelization.pdf:application/pdf},
}

@misc{narayanan_link_2011,
	title = {Link {Prediction} by {De}-anonymization: {How} {We} {Won} the {Kaggle} {Social} {Network} {Challenge}},
	shorttitle = {Link {Prediction} by {De}-anonymization},
	url = {http://arxiv.org/abs/1102.4374},
	doi = {10.48550/arXiv.1102.4374},
	abstract = {This paper describes the winning entry to the IJCNN 2011 Social Network Challenge run by Kaggle.com. The goal of the contest was to promote research on real-world link prediction, and the dataset was a graph obtained by crawling the popular Flickr social photo sharing website, with user identities scrubbed. By de-anonymizing much of the competition test set using our own Flickr crawl, we were able to effectively game the competition. Our attack represents a new application of de-anonymization to gaming machine learning contests, suggesting changes in how future competitions should be run. We introduce a new simulated annealing-based weighted graph matching algorithm for the seeding step of de-anonymization. We also show how to combine de-anonymization with link prediction---the latter is required to achieve good performance on the portion of the test set not de-anonymized---for example by training the predictor on the de-anonymized portion of the test set, and combining probabilistic predictions from de-anonymization and link prediction.},
	urldate = {2024-12-27},
	publisher = {arXiv},
	author = {Narayanan, Arvind and Shi, Elaine and Rubinstein, Benjamin I. P.},
	month = feb,
	year = {2011},
	note = {arXiv:1102.4374 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Cryptography and Security, kaggle},
	file = {Preprint PDF:/home/atomwalk12/Zotero/storage/MSE526D8/Narayanan et al. - 2011 - Link Prediction by De-anonymization How We Won the Kaggle Social Network Challenge.pdf:application/pdf;Snapshot:/home/atomwalk12/Zotero/storage/2SI3XQ5J/1102.html:text/html},
}

@article{barros_e_sa_deep_2024,
	title = {Deep reinforcement learning in real-time strategy games: a systematic literature review},
	volume = {55},
	issn = {1573-7497},
	shorttitle = {Deep reinforcement learning in real-time strategy games},
	url = {https://doi.org/10.1007/s10489-024-06220-4},
	doi = {10.1007/s10489-024-06220-4},
	abstract = {Reinforcement learning is a field of Machine Learning in which agents learn from interacting with the environment. These agents can deal with more complex problems when their decision-making process is combined with deep learning. While deep reinforcement learning can be used in many real-world applications, games often provide a good source of simulation environments for testing such algorithms. Among all game categories, real-time strategy games usually pose a difficult challenge since they have large state and action spaces, partial observation maps, sparse reward, and Multi-Agent problems, where the events occur continuously simultaneously. Thus, this paper provides a systematic literature review of deep reinforcement learning related to real-time strategy games. The main goals of this review are presented as follows: (a) identify the games used in recent works; (b) summarize the architectures and techniques used; (c) identify the simulation environments adopted and (d) understand whether the works focus on micromanagement or macromanagement tasks when dealing with real-time strategy games. The results show that some architectures have achieved better performance overall when handling both micro and macromanagement tasks, and that techniques for reducing the training time and the state space may improve the agents learning. This paper may help to guide future research on developing strategies to build agents for complex scenarios such as those faced in real-time strategy games.},
	language = {en},
	number = {3},
	urldate = {2024-12-30},
	journal = {Applied Intelligence},
	author = {Barros e Sá, Gabriel Caldas and Madeira, Charles Andrye Galvão},
	month = dec,
	year = {2024},
	keywords = {Agent architectures, Artificial Intelligence, Deep reinforcement learning, Real-time strategy games, Systematic literature review},
	pages = {243},
	file = {Full Text PDF:/home/atomwalk12/Zotero/storage/PD2XJWPE/Barros e Sá and Madeira - 2024 - Deep reinforcement learning in real-time strategy games a systematic literature review.pdf:application/pdf},
}

@article{dos_santos_sustainable_2024,
	title = {Sustainable systematic literature reviews},
	volume = {176},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584924001563},
	doi = {10.1016/j.infsof.2024.107551},
	abstract = {Context:
Systematic Literature Reviews (SLR) have been recognized as an important research method for summarizing evidence in Software Engineering (SE). At the same, SLR still presents several problems, such as the high resource consumption (mainly human resources) and lack of effective impact on SE practitioners, although much research has already been done.
Objective:
The main goal of this paper is to explore the concept of sustainability in the SLR area, intending to contribute to understanding better and solving such problems in an integrated way. More specifically, this paper characterizes what sustainable SLR are, their core characteristics, critical factors (i.e., sensitive points in the SLR process), and guidelines for conducting such SLR.
Methods:
We performed a meta-ethnographic study to find key concepts of sustainable software systems and transpose them to sustainable SLR. For this, we systematically selected 16 studies about sustainable software systems and 14 distinguished studies about SLR. Following, we extracted the main keywords and metaphors, determined how both areas are correlated, and transposed them to obtain a set of core characteristics of sustainable SLR as well as critical factors and guidelines. Additionally, we validated them with specialists using the Delphi method.
Results:
We found 15 core characteristics that offer a broad view of sustainable SLR, 15 critical factors in the SLR process that should be carefully addressed when conducting and updating SLR, and also 16 guidelines to manage SLR from the sustainability perspective.
Conclusion:
The concept of sustainability in SLR can contribute to solving SLR problems in a more integrated way, while this work could change the mindset of the SLR community about the need to conduct sustainable SLR.},
	urldate = {2024-12-31},
	journal = {Information and Software Technology},
	author = {dos Santos, Vinicius and Iwazaki, Anderson Y. and Felizardo, Katia R. and de Souza, Érica F. and Nakagawa, Elisa Y.},
	month = dec,
	year = {2024},
	keywords = {Systematic literature review, Secondary study, SLR, Sustainability},
	pages = {107551},
	file = {ScienceDirect Snapshot:/home/atomwalk12/Zotero/storage/MCEA5L9Z/S0950584924001563.html:text/html},
}

@article{bolanos_artificial_2024,
	title = {Artificial intelligence for literature reviews: opportunities and challenges},
	volume = {57},
	issn = {1573-7462},
	shorttitle = {Artificial intelligence for literature reviews},
	url = {https://doi.org/10.1007/s10462-024-10902-3},
	doi = {10.1007/s10462-024-10902-3},
	abstract = {This paper presents a comprehensive review of the use of Artificial Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous and organised methodology that assesses and integrates prior research on a given topic. Numerous tools have been developed to assist and partially automate the SLR process. The increasing role of AI in this field shows great potential in providing more effective support for researchers, moving towards the semi-automatic creation of literature reviews. Our study focuses on how AI techniques are applied in the semi-automation of SLRs, specifically in the screening and extraction phases. We examine 21 leading SLR tools using a framework that combines 23 traditional features with 11 AI features. We also analyse 11 recent tools that leverage large language models for searching the literature and assisting academic writing. Finally, the paper discusses current trends in the field, outlines key research challenges, and suggests directions for future research. We highlight three primary research challenges: integrating advanced AI solutions, such as large language models and knowledge graphs, improving usability, and developing a standardised evaluation framework. We also propose best practices to ensure more robust evaluations in terms of performance, usability, and transparency. Overall, this review offers a detailed overview of AI-enhanced SLR tools for researchers and practitioners, providing a foundation for the development of next-generation AI solutions in this field.},
	language = {en},
	number = {10},
	urldate = {2025-01-05},
	journal = {Artificial Intelligence Review},
	author = {Bolaños, Francisco and Salatino, Angelo and Osborne, Francesco and Motta, Enrico},
	month = aug,
	year = {2024},
	keywords = {Artificial Intelligence, Artificial intelligence, Evaluation framework, Large language models, Literature review, Natural anguage processing, Systematic literature reviews, Usability},
	pages = {259},
	file = {Full Text PDF:/home/atomwalk12/Zotero/storage/9XU7TFA7/Bolaños et al. - 2024 - Artificial intelligence for literature reviews opportunities and challenges.pdf:application/pdf},
}

@article{bolanos_artificial_2024-1,
	title = {Artificial intelligence for literature reviews: opportunities and challenges},
	volume = {57},
	issn = {1573-7462},
	shorttitle = {Artificial intelligence for literature reviews},
	url = {https://doi.org/10.1007/s10462-024-10902-3},
	doi = {10.1007/s10462-024-10902-3},
	abstract = {This paper presents a comprehensive review of the use of Artificial Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous and organised methodology that assesses and integrates prior research on a given topic. Numerous tools have been developed to assist and partially automate the SLR process. The increasing role of AI in this field shows great potential in providing more effective support for researchers, moving towards the semi-automatic creation of literature reviews. Our study focuses on how AI techniques are applied in the semi-automation of SLRs, specifically in the screening and extraction phases. We examine 21 leading SLR tools using a framework that combines 23 traditional features with 11 AI features. We also analyse 11 recent tools that leverage large language models for searching the literature and assisting academic writing. Finally, the paper discusses current trends in the field, outlines key research challenges, and suggests directions for future research. We highlight three primary research challenges: integrating advanced AI solutions, such as large language models and knowledge graphs, improving usability, and developing a standardised evaluation framework. We also propose best practices to ensure more robust evaluations in terms of performance, usability, and transparency. Overall, this review offers a detailed overview of AI-enhanced SLR tools for researchers and practitioners, providing a foundation for the development of next-generation AI solutions in this field.},
	language = {en},
	number = {10},
	urldate = {2025-01-05},
	journal = {Artificial Intelligence Review},
	author = {Bolaños, Francisco and Salatino, Angelo and Osborne, Francesco and Motta, Enrico},
	month = aug,
	year = {2024},
	keywords = {Artificial Intelligence, Artificial intelligence, Evaluation framework, Large language models, Literature review, Natural anguage processing, Systematic literature reviews, Usability},
	pages = {259},
	file = {Full Text PDF:/home/atomwalk12/Zotero/storage/HN75PDD9/Bolaños et al. - 2024 - Artificial intelligence for literature reviews opportunities and challenges.pdf:application/pdf},
}

@article{kitchenham_procedures_nodate,
	title = {Procedures for {Performing} {Systematic} {Reviews}},
	language = {en},
	author = {Kitchenham, Barbara},
	keywords = {literature-review},
	file = {PDF:/home/atomwalk12/Zotero/storage/8SUS6QW9/Kitchenham - Procedures for Performing Systematic Reviews.pdf:application/pdf},
}

@article{budgen_reporting_2018,
	title = {Reporting systematic reviews: {Some} lessons from a tertiary study},
	volume = {95},
	issn = {0950-5849},
	shorttitle = {Reporting systematic reviews},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584916303548},
	doi = {10.1016/j.infsof.2017.10.017},
	abstract = {Context
Many of the systematic reviews published in software engineering are related to research or methodological issues and hence are unlikely to be of direct benefit to practitioners or teachers. Those that are relevant to practice and teaching need to be presented in a form that makes their findings usable with minimum interpretation.
Objective
We have examined a sample of the many systematic reviews that have been published over a period of six years, in order to assess how well these are reported and identify useful lessons about how this might be done.
Method
We undertook a tertiary study, performing a systematic review of systematic reviews. Our study found 178 systematic reviews published in a set of major software engineering journals over the period 2010–2015. Of these, 37 provided recommendations or conclusions of relevance to education and/or practice and we used the DARE criteria as well as other attributes related to the systematic review process to analyse how well they were reported.
Results
We have derived a set of 12 ‘lessons’ that could help authors with reporting the outcomes of a systematic review in software engineering. We also provide an associated checklist for use by journal and conference referees.
Conclusion
There are several areas where better reporting is needed, including quality assessment, synthesis, and the procedures followed by the reviewers. Researchers, practitioners, teachers and journal referees would all benefit from better reporting of systematic reviews, both for clarity and also for establishing the provenance of any findings.},
	urldate = {2025-01-05},
	journal = {Information and Software Technology},
	author = {Budgen, David and Brereton, Pearl and Drummond, Sarah and Williams, Nikki},
	month = mar,
	year = {2018},
	keywords = {Provenance of findings, Reporting quality, Systematic review},
	pages = {62--74},
	file = {Accepted Version:/home/atomwalk12/Zotero/storage/SET4XTE6/Budgen et al. - 2018 - Reporting systematic reviews Some lessons from a tertiary study.pdf:application/pdf;ScienceDirect Snapshot:/home/atomwalk12/Zotero/storage/LAL2AWVY/S0950584916303548.html:text/html},
}

@article{brereton_lessons_2007,
	series = {Software {Performance}},
	title = {Lessons from applying the systematic literature review process within the software engineering domain},
	volume = {80},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S016412120600197X},
	doi = {10.1016/j.jss.2006.07.009},
	abstract = {A consequence of the growing number of empirical studies in software engineering is the need to adopt systematic approaches to assessing and aggregating research outcomes in order to provide a balanced and objective summary of research evidence for a particular topic. The paper reports experiences with applying one such approach, the practice of systematic literature review, to the published studies relevant to topics within the software engineering domain. The systematic literature review process is summarised, a number of reviews being undertaken by the authors and others are described and some lessons about the applicability of this practice to software engineering are extracted. The basic systematic literature review process seems appropriate to software engineering and the preparation and validation of a review protocol in advance of a review activity is especially valuable. The paper highlights areas where some adaptation of the process to accommodate the domain-specific characteristics of software engineering is needed as well as areas where improvements to current software engineering infrastructure and practices would enhance its applicability. In particular, infrastructure support provided by software engineering indexing databases is inadequate. Also, the quality of abstracts is poor; it is usually not possible to judge the relevance of a study from a review of the abstract alone.},
	number = {4},
	urldate = {2025-01-05},
	journal = {Journal of Systems and Software},
	author = {Brereton, Pearl and Kitchenham, Barbara A. and Budgen, David and Turner, Mark and Khalil, Mohamed},
	month = apr,
	year = {2007},
	keywords = {Systematic literature review, Empirical software engineering},
	pages = {571--583},
	file = {ScienceDirect Snapshot:/home/atomwalk12/Zotero/storage/V2L67PHV/S016412120600197X.html:text/html},
}

@article{brereton_lessons_2007-1,
	title = {Lessons from applying the systematic literature review process within the software engineering domain},
	volume = {80},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {01641212},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016412120600197X},
	doi = {10.1016/j.jss.2006.07.009},
	abstract = {A consequence of the growing number of empirical studies in software engineering is the need to adopt systematic approaches to assessing and aggregating research outcomes in order to provide a balanced and objective summary of research evidence for a particular topic. The paper reports experiences with applying one such approach, the practice of systematic literature review, to the published studies relevant to topics within the software engineering domain. The systematic literature review process is summarised, a number of reviews being undertaken by the authors and others are described and some lessons about the applicability of this practice to software engineering are extracted.},
	language = {en},
	number = {4},
	urldate = {2025-01-05},
	journal = {Journal of Systems and Software},
	author = {Brereton, Pearl and Kitchenham, Barbara A. and Budgen, David and Turner, Mark and Khalil, Mohamed},
	month = apr,
	year = {2007},
	pages = {571--583},
	file = {PDF:/home/atomwalk12/Zotero/storage/9U8H4DYF/Brereton et al. - 2007 - Lessons from applying the systematic literature review process within the software engineering domai.pdf:application/pdf},
}

@article{dos_santos_sustainable_2024-1,
	title = {Sustainable systematic literature reviews},
	volume = {176},
	issn = {09505849},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950584924001563},
	doi = {10.1016/j.infsof.2024.107551},
	abstract = {Objective: The main goal of this paper is to explore the concept of sustainability in the SLR area, intending to contribute to understanding better and solving such problems in an integrated way. More specifically, this paper characterizes what sustainable SLR are, their core characteristics, critical factors (i.e., sensitive points in the SLR process), and guidelines for conducting such SLR.
Methods: We performed a meta-ethnographic study to find key concepts of sustainable software systems and transpose them to sustainable SLR. For this, we systematically selected 16 studies about sustainable software systems and 14 distinguished studies about SLR. Following, we extracted the main keywords and metaphors, determined how both areas are correlated, and transposed them to obtain a set of core characteristics of sustainable SLR as well as critical factors and guidelines. Additionally, we validated them with specialists using the Delphi method.
Results: We found 15 core characteristics that offer a broad view of sustainable SLR, 15 critical factors in the SLR process that should be carefully addressed when conducting and updating SLR, and also 16 guidelines to manage SLR from the sustainability perspective.
Conclusion: The concept of sustainability in SLR can contribute to solving SLR problems in a more integrated way, while this work could change the mindset of the SLR community about the need to conduct sustainable SLR.},
	language = {en},
	urldate = {2025-01-05},
	journal = {Information and Software Technology},
	author = {Dos Santos, Vinicius and Iwazaki, Anderson Y. and Felizardo, Katia R. and De Souza, Érica F. and Nakagawa, Elisa Y.},
	month = dec,
	year = {2024},
	pages = {107551},
	file = {PDF:/home/atomwalk12/Zotero/storage/H3SLL832/Dos Santos et al. - 2024 - Sustainable systematic literature reviews.pdf:application/pdf},
}

@article{dehghani_distributed_2023,
	title = {From distributed machine to distributed deep learning: a comprehensive survey},
	volume = {10},
	issn = {2196-1115},
	shorttitle = {From distributed machine to distributed deep learning},
	url = {https://doi.org/10.1186/s40537-023-00829-x},
	doi = {10.1186/s40537-023-00829-x},
	abstract = {Artificial intelligence has made remarkable progress in handling complex tasks, thanks to advances in hardware acceleration and machine learning algorithms. However, to acquire more accurate outcomes and solve more complex issues, algorithms should be trained with more data. Processing this huge amount of data could be time-consuming and require a great deal of computation. To address these issues, distributed machine learning has been proposed, which involves distributing the data and algorithm across several machines. There has been considerable effort put into developing distributed machine learning algorithms, and different methods have been proposed so far. We divide these algorithms in classification and clustering (traditional machine learning), deep learning and deep reinforcement learning groups. Distributed deep learning has gained more attention in recent years and most of the studies have focused on this approach. Therefore, we mostly concentrate on this category. Based on the investigation of the mentioned algorithms, we highlighted the limitations that should be addressed in future research.},
	language = {en},
	number = {1},
	urldate = {2025-01-05},
	journal = {Journal of Big Data},
	author = {Dehghani, Mohammad and Yazdanparast, Zahra},
	month = oct,
	year = {2023},
	keywords = {Artificial Intelligence, Artificial intelligence, Data-parallelism, Distributed deep learning, Distributed machine learning, Ditributed reinforcement learning, Machine learning, Model-parallelism},
	pages = {158},
	file = {Full Text PDF:/home/atomwalk12/Zotero/storage/FQPFJL85/Dehghani and Yazdanparast - 2023 - From distributed machine to distributed deep learning a comprehensive survey.pdf:application/pdf},
}

@inproceedings{berloco_systematic_2022,
	address = {Cham},
	title = {A {Systematic} {Review} of {Distributed} {Deep} {Learning} {Frameworks} for {Big} {Data}},
	isbn = {978-3-031-13832-4},
	doi = {10.1007/978-3-031-13832-4_21},
	abstract = {Traditional Machine Learning and Deep Learning techniques (data acquisition, preparation, model training and evaluation) take a lot of computational resources and time to produce even a simple prediction model, especially when implemented on a single machine. Intuitively, the demand for computational requirements is higher in case of management of Big Data and training of complex models. Thus, a paradigm shift from a single machine to a BD-oriented approach is required for making traditional Machine Learning and Deep Learning techniques fit to Big Data. In particular, it emerges the need for developing and deploying Big Data Analytics Infrastructures on cluster of machines. In this context, main features and principles of Distributed Deep Learning frameworks are here discussed. The main contribution of this paper is a systematic review of proposed solutions, aimed at investigating under a unifying lens their foundational elements, functional features and capabilities, despite the inherent literature fragmentation. To this, we conducted a literature search in Scopus and Google Scholar. This review also compares Distributed Deep Learning approaches according to more technical facets: implemented of parallelism techniques, supported hardware, model parameters sharing modalities, computation modalities for stochastic gradient descent and compatibility with other frameworks.},
	language = {en},
	booktitle = {Intelligent {Computing} {Methodologies}},
	publisher = {Springer International Publishing},
	author = {Berloco, Francesco and Bevilacqua, Vitoantonio and Colucci, Simona},
	editor = {Huang, De-Shuang and Jo, Kang-Hyun and Jing, Junfeng and Premaratne, Prashan and Bevilacqua, Vitoantonio and Hussain, Abir},
	year = {2022},
	keywords = {Big Data, Distributed Deep Learning, Distributed Deep Learning Frameworks, Parallel computing},
	pages = {242--256},
	file = {Full Text PDF:/home/atomwalk12/Zotero/storage/PJJTIG7E/Berloco et al. - 2022 - A Systematic Review of Distributed Deep Learning Frameworks for Big Data.pdf:application/pdf},
}

@article{langer_distributed_2020,
	title = {Distributed {Training} of {Deep} {Learning} {Models}: {A} {Taxonomic} {Perspective}},
	volume = {31},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1045-9219, 1558-2183, 2161-9883},
	shorttitle = {Distributed {Training} of {Deep} {Learning} {Models}},
	url = {https://ieeexplore.ieee.org/document/9120226/},
	doi = {10.1109/TPDS.2020.3003307},
	abstract = {Distributed deep learning systems (DDLS) train deep neural network models by utilizing the distributed resources of a cluster. Developers of DDLS are required to make many decisions to process their particular workloads in their chosen environment efficiently. The advent of GPU-based deep learning, the ever-increasing size of datasets, and deep neural network models, in combination with the bandwidth constraints that exist in cluster environments require developers of DDLS to be innovative in order to train high-quality models quickly. Comparing DDLS side-by-side is difficult due to their extensive feature lists and architectural deviations. We aim to shine some light on the fundamental principles that are at work when training deep neural networks in a cluster of independent machines by analyzing the general properties associated with training deep learning models and how such workloads can be distributed in a cluster to achieve collaborative model training. Thereby we provide an overview of the different techniques that are used by contemporary DDLS and discuss their influence and implications on the training process. To conceptualize and compare DDLS, we group different techniques into categories, thus establishing a taxonomy of distributed deep learning systems.},
	number = {12},
	urldate = {2025-01-05},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Langer, Matthias and He, Zhen and Rahayu, Wenny and Xue, Yanbo},
	month = dec,
	year = {2020},
	pages = {2802--2818},
	file = {Submitted Version:/home/atomwalk12/Zotero/storage/4649MWFD/Langer et al. - 2020 - Distributed Training of Deep Learning Models A Taxonomic Perspective.pdf:application/pdf},
}

@misc{nichols_survey_2022-1,
	title = {A {Survey} and {Empirical} {Evaluation} of {Parallel} {Deep} {Learning} {Frameworks}},
	url = {http://arxiv.org/abs/2111.04949},
	doi = {10.48550/arXiv.2111.04949},
	abstract = {The field of deep learning has witnessed a remarkable shift towards extremely compute- and memory-intensive neural networks. These newer larger models have enabled researchers to advance state-of-the-art tools across a variety of fields. This phenomenon has spurred the development of algorithms for distributed training of neural networks over a larger number of hardware accelerators. In this paper, we discuss and compare current state-of-the-art frameworks for large scale distributed deep learning. First, we survey current practices in distributed learning and identify the different types of parallelism used. Then, we present empirical results comparing their performance on large image and language training tasks. Additionally, we address their statistical efficiency and memory consumption behavior. Based on our results, we discuss algorithmic and implementation portions of each framework which hinder performance.},
	urldate = {2025-01-05},
	publisher = {arXiv},
	author = {Nichols, Daniel and Singh, Siddharth and Lin, Shu-Huai and Bhatele, Abhinav},
	month = jul,
	year = {2022},
	note = {arXiv:2111.04949 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/home/atomwalk12/Zotero/storage/U3PUQJSE/Nichols et al. - 2022 - A Survey and Empirical Evaluation of Parallel Deep Learning Frameworks.pdf:application/pdf;Snapshot:/home/atomwalk12/Zotero/storage/XYGZ2AQZ/2111.html:text/html},
}

@misc{xing_strategies_2015,
	title = {Strategies and {Principles} of {Distributed} {Machine} {Learning} on {Big} {Data}},
	url = {http://arxiv.org/abs/1512.09295},
	doi = {10.48550/arXiv.1512.09295},
	abstract = {The rise of Big Data has led to new demands for Machine Learning (ML) systems to learn complex models with millions to billions of parameters, that promise adequate capacity to digest massive datasets and offer powerful predictive analytics thereupon. In order to run ML algorithms at such scales, on a distributed cluster with 10s to 1000s of machines, it is often the case that significant engineering efforts are required --- and one might fairly ask if such engineering truly falls within the domain of ML research or not. Taking the view that Big ML systems can benefit greatly from ML-rooted statistical and algorithmic insights --- and that ML researchers should therefore not shy away from such systems design --- we discuss a series of principles and strategies distilled from our recent efforts on industrial-scale ML solutions. These principles and strategies span a continuum from application, to engineering, and to theoretical research and development of Big ML systems and architectures, with the goal of understanding how to make them efficient, generally-applicable, and supported with convergence and scaling guarantees. They concern four key questions which traditionally receive little attention in ML research: How to distribute an ML program over a cluster? How to bridge ML computation with inter-machine communication? How to perform such communication? What should be communicated between machines? By exposing underlying statistical and algorithmic characteristics unique to ML programs but not typically seen in traditional computer programs, and by dissecting successful cases to reveal how we have harnessed these principles to design and develop both high-performance distributed ML software as well as general-purpose ML frameworks, we present opportunities for ML researchers and practitioners to further shape and grow the area that lies between ML and systems.},
	urldate = {2025-01-05},
	publisher = {arXiv},
	author = {Xing, Eric P. and Ho, Qirong and Xie, Pengtao and Dai, Wei},
	month = dec,
	year = {2015},
	note = {arXiv:1512.09295 [stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing, Statistics - Machine Learning},
	file = {Preprint PDF:/home/atomwalk12/Zotero/storage/RHYCBQMX/Xing et al. - 2015 - Strategies and Principles of Distributed Machine Learning on Big Data.pdf:application/pdf;Snapshot:/home/atomwalk12/Zotero/storage/GWFZVF5U/1512.html:text/html},
}

@article{vasile_survey_nodate,
	title = {Survey on {Distributed} {Techniques} applied to {Neural} {Networks}},
	language = {en},
	author = {Vasile, Razvan Florian},
	file = {PDF:/home/atomwalk12/Zotero/storage/HE8WRHGK/Vasile - Survey on Distributed Techniques applied to Neural Networks.pdf:application/pdf},
}

}

@article{brereton_lessons_2007,
	series = {Software {Performance}},
	title = {Lessons from applying the systematic literature review process within the software engineering domain},
	volume = {80},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S016412120600197X},
	doi = {10.1016/j.jss.2006.07.009},
	abstract = {A consequence of the growing number of empirical studies in software engineering is the need to adopt systematic approaches to assessing and aggregating research outcomes in order to provide a balanced and objective summary of research evidence for a particular topic. The paper reports experiences with applying one such approach, the practice of systematic literature review, to the published studies relevant to topics within the software engineering domain. The systematic literature review process is summarised, a number of reviews being undertaken by the authors and others are described and some lessons about the applicability of this practice to software engineering are extracted. The basic systematic literature review process seems appropriate to software engineering and the preparation and validation of a review protocol in advance of a review activity is especially valuable. The paper highlights areas where some adaptation of the process to accommodate the domain-specific characteristics of software engineering is needed as well as areas where improvements to current software engineering infrastructure and practices would enhance its applicability. In particular, infrastructure support provided by software engineering indexing databases is inadequate. Also, the quality of abstracts is poor; it is usually not possible to judge the relevance of a study from a review of the abstract alone.},
	number = {4},
	urldate = {2025-01-05},
	journal = {Journal of Systems and Software},
	author = {Brereton, Pearl and Kitchenham, Barbara A. and Budgen, David and Turner, Mark and Khalil, Mohamed},
	month = apr,
	year = {2007},
	keywords = {Systematic literature review, Empirical software engineering},
	pages = {571--583},
	file = {ScienceDirect Snapshot:/home/atomwalk12/Zotero/storage/V2L67PHV/S016412120600197X.html:text/html},
}

% Two papers from the project proposal below
@article{SierraCanto2010ParallelTO,
  title={Parallel Training of a Back-Propagation Neural Network Using CUDA},
  author={Xavier Sierra-Canto and Francisco Madera-Ramirez and V{\'i}ctor Uc Cetina},
  journal={2010 Ninth International Conference on Machine Learning and Applications},
  year={2010},
  pages={307-312},
  url={https://api.semanticscholar.org/CorpusID:53717101}
}

@misc{li2020pytorchdistributedexperiencesaccelerating,
      title={PyTorch Distributed: Experiences on Accelerating Data Parallel Training}, 
      author={Shen Li and Yanli Zhao and Rohan Varma and Omkar Salpekar and Pieter Noordhuis and Teng Li and Adam Paszke and Jeff Smith and Brian Vaughan and Pritam Damania and Soumith Chintala},
      year={2020},
      eprint={2006.15704},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/2006.15704}, 
}