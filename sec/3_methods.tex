% ===== STEP 4: Skimming the Studies =====
% This section covers:
% - Initial screening process
% - Detailed in Section 2.2.1 (Study 1)
% - Detailed in Section 3.2 (Study 2)
\section{Methods}
\label{sec:methods}

% PLACEHOLDER: Study Selection Process
\TODO{PLACEHOLDER: Study Selection Process}
\subsection{Study Selection Process}
\subsubsection{Initial Screening}
Papers were initially screened based on:
\begin{itemize}
    \item Title and abstract relevance
    \item Citation count and venue quality
    \item Implementation details availability
\end{itemize}

% PLACEHOLDER: Study 1 Details
\TODO{PLACEHOLDER: Study 1 Details}
\subsection{Distributed Learning Analysis}
\subsubsection{Selection Criteria}
\begin{itemize}
    \item Clear description of distributed architecture
    \item Empirical performance measurements
    \item Scalability analysis
    \item Comparison with baseline methods
\end{itemize}

% PLACEHOLDER: Study 2 Details
\TODO{PLACEHOLDER: Study 2 Details}
\subsection{CUDA Implementation Analysis}
\subsubsection{Selection Criteria}
\begin{itemize}
    \item Detailed CUDA implementation description
    \item Performance benchmarks
    \item Memory usage analysis
    \item Optimization techniques
\end{itemize}

\TODO{Placeholder-end}


\TODO{PLACEHOLDER: Study 3 Details}

\section{GPU programming}
\textbf{TensorRT.}
NVIDIA® TensorRT™ is an SDK that facilitates high performance machine learning
inference. It is designed to work in a complementary fashion with training frameworks
such as TensorFlow, PyTorch, and MXNet. It focuses specifically on running an already-trained 
network quickly and efficiently on NVIDIA hardware.

A Pytorch implementation of Sparsely Gated Mixture of Experts, for massively 
increasing the capacity (parameter count) of a language model while keeping 
the computation constant.
https://github.com/lucidrains/mixture-of-experts?

https://cloud.google.com/products/ai

https://github.com/tensorflow/lingvo/tree/master/lingvo/tasks/lm